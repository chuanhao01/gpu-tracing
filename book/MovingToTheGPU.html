<meta charset="utf-8">
<link rel="icon" type="image/png" href="../favicon.png">
<!-- Markdeep: https://casual-effects.com/markdeep/ -->

                                  **Ray Tracing: Moving to the GPU**
                                           [Arman Uguray][]
                                                <br>
                                                Draft
                                                <br>

Introduction
====================================================================================================
_Ray Tracing_ is a rendering method that simulates the flow of light. It can faithfully recreate a
variety of optical phenomena and can be used to render photorealistic images. It is one of the
foundational techniques in Computer Graphics used to model light transport.

_Path tracing_ is an application of this approach in order to compute _Global Illumination_. Its
core idea is to repeatedly trace millions of random rays through the scene and bounce them off
objects based on surface properties. The algorithm is remarkably simple and it is relatively easy
to build a basic path tracer that supports a small number of material and geometry types. Peter
Shirley's [_Ray Tracing In One Weekend_][RTIOW] shows you how to get started with a CPU path tracer
in a quick and enjoyable way.

A big challenge with path tracing is its high computational cost. Rendering a complex scene takes a
long time and this get worse as complexity increases. This has historically made path
tracing unsuitable for real-time applications. Fortunately -- like many problems in Computer
Graphics -- the algorithm lends itself very well to parallelism and it is possible to achieve a
significant speedup by distributing the work across many processor cores. This brings us to GPUs.

The GPU (Graphics Processing Unit) is a type of processor designed to run the same set of oparations
over large amounts of data in parallel. This parallelism has been instrumental to achieving
realistic visuals in real-time applications like video games. GPUs were traditionally used to
accelerate _scanline rasterization_ but they have since become programmable and capable of running
a variety of parallel workloads. Notably, dedicated hardware cores to accelerate ray tracing are
becoming more common in modern GPUs.

GPUs aren't without limitations. Targeting a GPU requires you to program in a way that is different
from how you would typically approach a CPU program. Taking full advantage of the hardware requires
very careful tuning based on its architecture and capabilities (which can vary widely across GPU
vendors and models). Rendering fully path-traced scenes at real-time rates remains elusive even on
the most high-end GPUs and is an active and vibrant area of research.

This book is an introduction to GPU programming by building a simple GPU accelerated path tracer.
We'll focus on building a renderer that can produce high quality and correct images using a fairly
simple design. It won't be full-featured and its performance will be limited but it will expose you
to several fundamental GPU programming concepts. The renderer you'll have built by the end can serve
as a great starting point for extensions and experiments with more advanced GPU techniques. We will
avoid most optimizations in favor of simplicity but the renderer will be able to achieve interactive
frame rates on a decent GPU.[^ch1]

The book follows a similar progression to [_Ray Tracing In One Weekend_][RTIOW]. I cover some of
the same material but I highly recommend completing _RTIOW_ before embarking on building
the GPU version since doing so will teach you the path tracing algorithm in a much more approachable
way and it will make you appreciate both the advantages and challenges of moving to a GPU-based
architecture.

If you run into any problems with your implementation, have general questions or corrections, or
would like to share own ideas or work, check out [the GitHub Discussions forum][discussions].

Finally, I'd like to extend a special thank you to [Steve Hollasch][] and [Trevor David Black][] for
their guidance and for allowing me to host this book under the [RayTracing GitHub
project][rt-project].

[^ch1]: A BVH-accelerated implementation can render a version of the RTIOW cover scene with ~32,000
spheres, 16 ray bounces per pixel, and a resolution of 2048x1536 on a 2022 _Apple M1 Max_ in 15
milliseconds. The same renderer performs very poorly on a 2019 _Intel UHD Graphics 630_ which takes
more than 200ms to render a single sample.

GPU APIs
--------
Interfacing with a GPU and writing programs for it typically requires the use of a special API. This
interface depends on your operating system and GPU vendor. You often have various options depending
on the capabilities you want. For example, an application that wants to get the most juice out of a
NVIDIA GPU for general purpose computations may choose to target CUDA, while a developer who prefers
broad hardware compatibility for a graphical mobile game may choose OpenGL ES or Vulkan. Direct3D
(D3D) is the main graphics API on Microsoft platforms while Metal is the preferred framework on
systems from Apple. Vulkan, D3D12, and Metal even support an API specifically to accelerate ray
tracing.

You can implement this book using any API or framework that you prefer, though I generally assume
that you are working with a graphics API. In my examples I use an API based on [WebGPU][webgpu]
which I think maps well to all modern graphics APIs like Metal, Vulkan, and D3D12. The code
examples should be easy to adapt to those libraries. I avoided using ray tracing APIs (such as
[DXR][dxr] or [Vulkan Ray Tracing][vkrt]) to show you how to implement similar functionality on
your own.

<!-- TODO: Maybe this is better to list in a references section at the bottom -->
If you're looking to implement this in CUDA, you may also be interested in Roger Allen's
[blog post][rtiow-cuda] titled _Accelerated Ray Tracing in One Weekend in CUDA_.

Example Code
------------
Like _Ray Tracing In One Weekend_, you'll find code examples throughout the book. I use [Rust][] as
the driving language but you can choose any language that supports your GPU API of choice. I avoid
most esoteric aspects of Rust to keep the code easily understandable to a large audience. On the few
occasions where I had to resort to a potentially unfamiliar Rust-ism, I provide a C example to add
clarity.

I provide the finished source code for this book on [GitHub][gt-project] as a reference but I
encourage you to type in your own code. I decided to also provide a minimal source template that you
can use as a starting point if you want to follow along in Rust. The template provides a small
amount of setup code for the windowing logic to help get you started.

### A note on Rust, Libraries, and APIs

I chose Rust for this project because of its ease of use and portability. It also happens to be the
language that I tend to be most productive in.

An important aspect of Rust is that a lot of common functionality is provided by libraries outside
its standard library. I tried to avoid external dependencies as much as possible except for the
following:

* I use *[wgpu][]* to interact with the GPU. This is a native graphics API based on
  WebGPU. It's portable and allows the example code to run on Vulkan, Metal, Direct3D 11/12, OpenGL
  ES 3.1, as well as WebGPU and WebGL via WebAssembly.

  wgpu also has [native bindings in other languages](https://github.com/gfx-rs/wgpu-native).

* I use [*winit*](https://docs.rs/winit/latest/winit/) which is a portable windowing library. I use
  it to view the rendered image in real-time and to make the example code interactive.

* For ease of Rust development I use [*anyhow*](https://docs.rs/anyhow/latest/anyhow/) and
  [*bytemuck*](https://docs.rs/bytemuck/latest/bytemuck/). *anyhow* is a popular error handling
  utility and integrates seamlessly. *bytemuck* provides a safe abstraction for the equivalent of
  `reinterpret_cast` in C++, which normally requires [`unsafe`][rust-unsafe] Rust. I use it to
  bridge CPU data types with their GPU equivalents.

* Lastly, I use [*pollster*](https://docs.rs/pollster/latest/pollster/) to execute asynchronous
  wgpu API functions (which is only called from a single line).

[wgpu][] is the most important dependency as it defines how the example code  interacts with the
GPU. Every GPU API is different but their abstractions for the general concepts used in this book
are fairly similar. I will highlight these differences occasionally where they matter.

A large portion of the example code runs on the GPU. Every graphics API defines a programming
language -- a so called **shading language** -- for authoring GPU programs. wgpu is based on WebGPU,
as such my GPU code examples are written in the *WebGPU Shading Language* (WGSL)[^ch1.2.1].
<!-- Have GLSL examples too? -->

The [wgpu API documentation](https://docs.rs/wgpu/latest/wgpu/) and the
[WebGPU](https://www.w3.org/TR/webgpu/) and [WGSL](https://www.w3.org/TR/WGSL/) specifications are
great references to keep handy when you're
developing.

With all of that out of the way, let's get started!

[^ch1.2.1]: wgpu also supports shaders in the
[SPIR-V](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html) binary format. You could
in theory write your shaders in a shading language that can compile to SPIR-V (such as OpenGL's GLSL
and Direct3D's HLSL) as long as you avoid any language features that can't be expressed in WGSL.

Windowing and GPU Setup
====================================================================================================
The first thing to decide is how you want to view your image. One option is to write the output from
the GPU to a file. I think a more fun option is to display the image inside an application window.
I prefer this approach because it allows you to see your rendering as it resolves over time and it
will allow you to make your application interactive later on. The downside is that it requires a
little bit of wiring.

First, your program needs a way to interact with your operating system to create and manage a
window. Next, you need a way to coordinate your GPU workloads to output a sequence of images at the
right time for your OS to be able to composite it inside the window and send it to your display.

Every operating system with a graphical UI provides a native *windowing API* for this purpose.
Graphics APIs typically define some way to integrate with a windowing system. You'll have various
libraries to choose from depending on your OS and programming language. You mainly need to make sure
that the windowing API or UI toolkit you choose can integrate with your graphics API.

In my examples I use *winit* which is a Rust framework that integrates smoothly with wgpu. I put
together a [project template][gt-template] that sets up the library boilerplate for the window
handling. You're welcome to use it as a starting point.

The setup code isn't a lot, so I'll briefly go over the important pieces in this chapter.

The Event Loop
--------------
The first thing the template does is create a window and associate it with an *event loop*. The OS
sends a message to the application during important "events" that the application should act on,
such as a mouse click or when the window gets resized. Your application can wait for these events
and handle them as they arrive by looping indefinitely:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    use {
        anyhow::{Context, Result},
        winit::{
            event::{Event, WindowEvent},
            event_loop::{ControlFlow, EventLoop},
            window::WindowBuilder,
        },
    };

    const WIDTH: u32 = 800;
    const HEIGHT: u32 = 600;

    fn main() -> Result&lt()&gt {
        let event_loop = EventLoop::new();
        let window_size = winit::dpi::PhysicalSize::new(WIDTH, HEIGHT);
        let window = WindowBuilder::new()
            .with_inner_size(window_size)
            .with_title("GPU Path Tracer".to_string())
            .build(&event_loop)?;

        // TODO: initialize renderer

        event_loop.run(move |event, _, control_flow| {
            *control_flow = ControlFlow::Poll;
            match event {
                Event::WindowEvent { event, .. } => {
                    if event == WindowEvent::CloseRequested {
                        *control_flow = ControlFlow::Exit;
                    }
                }
                Event::RedrawRequested(_) => {
                    // TODO: draw frame
                }
                Event::MainEventsCleared => {
                    // draw repeatedly
                    window.request_redraw();
                }
                _ => ()
            }
        });
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-initial]: <kbd>[main.rs]</kbd> Creating a window and handling window events]

This code creates a window titled "GPU Path Tracer" and kicks off an event loop.
`event_loop.run()` internally waits for window events and notifies your application by calling the
lambda function that it gets passed as an argument.

The lambda function only handles a few events for now. The most important one is `RedrawRequested`
which is the signal to render and present a new frame. `MainEventsCleared` is simply an event that
gets sent when all pending events have been processed. We call `window.request_redraw()` to draw
repeatedly -- this triggers a new `RedrawRequested` event which is followed by another
`MainEventsCleared`, which requests a redraw,  and so on until someone closes the window.

Running this code should bring up an empty window like this:

  ![Figure [empty-window]: Empty Window](../images/img-01-empty-window.png)

GPU and Surface Initialization
------------------------------
The next thing the template does is establish a connection to the GPU and configure a surface. The
surface manages a set of *textures* that allow the GPU to render inside the window.

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    async fn connect_to_gpu(window: &Window) -> Result&lt(wgpu::Device, wgpu::Queue, wgpu::Surface&gt {
        use wgpu::TextureFormat::{Bgra8Unorm, Rgba8Unorm};
        // Create an "instance" of wgpu. This is the entry-point to the API.
        let instance = wgpu::Instance::default();

        // Create a drawable "surface" that is associated with the window.
        let surface = unsafe { instance.create_surface(&window) }?;

        // Request a GPU that is compatible with the surface. If the system has multiple GPUs then
        // pick the high performance one.
        let adapter = instance
            .request_adapter(&wgpu::RequestAdapterOptions {
                power_preference: wgpu::PowerPreference::HighPerformance,
                force_fallback_adapter: false,
                compatible_surface: Some(&surface),
            })
            .await
            .context("failed to find a compatible adapter")?;

        // Connect to the GPU. "device" represents the connection to the GPU and allows us to create
        // resources like buffers, textures, and pipelines. "queue" represents the command queue that
        // we use to submit commands to the GPU.
        let (device, queue) = adapter
            .request_device(&wgpu::DeviceDescriptor::default(), None)
            .await
            .context("failed to connect to the GPU")?;

        // Configure the texture memory backs the surface. Our renderer will draw to a surface texture
        // every frame.
        let caps = surface.get_capabilities(&adapter);
        let format = caps
            .formats
            .into_iter()
            .find(|it| matches!(it, Rgba8Unorm | Bgra8Unorm))
            .context("could not find preferred texture format (Rgba8Unorm or Bgra8Unorm)")?;
        let size = window.inner_size();
        let config = wgpu::SurfaceConfiguration {
            usage: wgpu::TextureUsages::RENDER_ATTACHMENT,
            format,
            width: size.width,
            height: size.height,
            present_mode: wgpu::PresentMode::AutoVsync,
            alpha_mode: caps.alpha_modes[0],
            view_formats: vec![],
        };
        surface.configure(&device, &config);

        Ok((device, queue, surface))
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-initial]: <kbd>[main.rs]</kbd> The connect_to_gpu function]

The code that sets this all up is a bit wordy. I'll quickly go over the important bits:

1. What the first ~20 lines do is request a connection to a GPU that is compatible with the
   window. The bit about `wgpu::PowerPreference::HighPerformance` is a hint to the API that we want
   the higher-powered GPU if the current system has more than one available.

2. The rest of the function configures the dimensions, pixel format, and presentation mode of the
   surface. `Rgba8Unorm` and `Bgra8Unorm` are common pixel formats that store each color component
   (red, green, blue, and alpha) as an 8-bit unsigned integer. The "unorm" part stands for "unsigned
   normalized", which means that our rendering code can represent the component values as a real
   number in the range `[0.0, 1.0]`. We set the size to simply span the entire window.

   The bit about `wgpu::PresentMode::AutoVsync` tells the surface to synchronize the presentation of
   each frame with the display's refresh rate. The surface will manage an internal queue of textures
   for us and we will render to them as they become available. This prevents a visual artifact known
   as "tearing" (which can happen when frames get presented faster than the display refresh rate) by
   setting up the renderer to be *v-sync locked*. We will discuss some of the implications of this
   later on.

   The last bit that I'll highlight here is `wgpu::TextureUsage::RENDER_ATTACHMENT`. This just
   indicates that we are going to use the GPU's rendering function to draw directly into the surface
   textures.

After setting all this up the function returns 3 objects: A `wgpu::Device` that represents the
connection to the GPU, a `wgpu::Queue` which we'll use to issue commands to the GPU, and a
`wgpu::Surface` that we'll use to present frames to the window. We will talk a lot about the first
two when we start putting together our renderer in the next chapter.

You may have noticed that the function declaration begins with `async`. This marks the function as
*asynchronous* which means that it doesn't return its result immediately. This is only necessary
because the API functions that we invoke (`wgpu::Instance::request_adapter` and
`wgpu::Adapter::request_device`) are asynchronous functions. The `.await` keyword is syntactic sugar
that makes the asynchronous calls appear like regular (synchronous) function calls. What happens
under the hood is somewhat complex but I wouldn't worry about this too much since this is the one
and only bit of asynchronous code that we will encounter. If you want to learn more about it, I
recommend checking out the [Rust Async Book](https://rust-lang.github.io/async-book/).

### Completing Setup

Finally, the `main` function needs a couple updates: first we make it `async` so that it we can
"await" on `connect_to_gpu`. Technically the `main` function of a program cannot be async and
running an async function requires some additional utilities. There are various alternatives but I
chose to use a library called `pollster`. The library provides a special macro (called `main`) that
takes care of everything. Again, this is the only asynchronous code that we'll encounter so don't
worry about what it does.

The second change to the main function is where it handles the `RedrawRequested` event. For every
new frame, we first request the next available texture from the surface that we just created. The
queue has a limited number of textures available. If the CPU outpaces the GPU (i.e. the GPU takes
longer than a display refresh cycle to finish its tasks), then calling
`surface.get_current_texture()` can block until a texture becomes available.

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
    #[pollster::main]
    async fn main() -> Result&lt()&gt {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
        let event_loop = EventLoop::new();
        let window_size = winit::dpi::PhysicalSize::new(WIDTH, HEIGHT);
        let window = WindowBuilder::new()
            .with_inner_size(window_size)
            .with_title("GPU Path Tracer".to_string())
            .build(&event_loop)?;

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
        let (device, queue, surface) = connect_to_gpu(&window).await?;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
        // TODO: initialize renderer

        event_loop.run(move |event, _, control_flow| {
            *control_flow = ControlFlow::Poll;
            match event {
                Event::WindowEvent { event, .. } => match event {
                    WindowEvent::CloseRequested => *control_flow = ControlFlow::Exit,
                    _ => (),
                }
                Event::RedrawRequested(_) => {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
                    // Wait for the next available frame buffer.
                    let frame: wgpu::SurfaceTexture = surface
                        .get_current_texture()
                        .expect("failed to get current texture");


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
                    // TODO: draw frame
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight

                    frame.present();
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
                }
                Event::MainEventsCleared => {
                    // draw repeatedly
                    window.request_redraw();
                }
                _ => ()
            }
        });
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-setup-complete]: <kbd>[main.rs]</kbd> Putting together the initial main function]

Once a frame texture becomes available, the example issues a request to display it as soon as
possible by calling `frame.present()`. All of our rendering work will be scheduled before this call.

That was a lot of boilerplate -- this is sometimes necessary to interact with OS resources. With all
of this in place, we can start building a real-time renderer.

### A note on error handling in Rust
If you're new to Rust, some of the patterns above may look unfamiliar. One of these is error
handling using the `Result` type. I use this pattern frequently enough that it's worth a quick
explainer.

A `Result` is a variant type that can hold either a success (`Ok`) value or an error (`Err`) value.
The types of the `Ok` and `Err` variants are generic:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    pub enum Result&ltT, E&gt {
        Ok(T),
        Err(E),
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Figure [rust-result]: The `Result` type]

`T` and `E` can be any type. It's common for a library to define its own error types to represent
various error conditions.

The idea is that a function returns a `Result` if it has a failure mode. A caller must check the
status of the `Result` to unpack the return value or recover from an error.

In a C program, a common way to handle an error is to return early from the calling function and
and perhaps return an entirely new error. For example:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C
    bool function_with_a_result(Foo* out_result);

    int main() {
        Foo foo;
        if (!function_with_result(&foo)) {
            return -1;
        }

        // ...do something with `foo`...

        return 0;
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Rust provides the `?` operator to automatically unpack a `Result` and return early if it holds an
error. A Rust version of the C program above could be written like this:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    fn function_with_result() -> Result&ltFoo, FooError&gt {...}

    fn caller() -> Result&lt(), FooError&gt {
        let foo: Foo = function_with_result()?;

        // ...do something with `foo`...

        Ok(())
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If `function_with_result()` returns an error, the `?` operator will cause `caller` to return and
propagate the error value. This works as long as `caller` and `function_with_result` either return
the same error type or types with a known conversion. There are various other ways to handle an
error:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    fn function_with_result() -> Result&ltFoo, FooError&gt {...}

    fn caller() -> Result&lt(), BarError&gt {
        ...
        if let Err(e) = function_with_result() {
            println!("got a foo error: {:?}", e);
            return Err(BarError::from_foo(e));
        }
        ...
        let foo = function_with_result().map_err(BarError::from_foo)?;
        ...
        let Ok(foo) = function_with_result() else {
            panic!("Didn't work the second time");
        }
        ...
        let foo = match function_with_result() {
            Ok(foo) => foo,
            Err(e) => panic!("failed again");
        };
        ...
        Ok(())
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

I like to keep things simple in my code examples and use the `?` operator. Instead of defining
custom error types and conversions, I use a catch all `Error` type from a library called *anyhow*.
You'll often see the examples include `anyhow::Result` (an alias for `Result&ltT, anyhow::Error&gt`)
and `anyhow::Context`. The latter is useful for adding an error message while converting to an
`anyhow::Error`:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    fn caller() -> anyhow::Result&lt()&gt {
        let foo: Foo = function_with_result().context("failed to get foo")?;

        // ...do something with `foo`...

        Ok(())
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You can read more about the `Result` type in [its module
documentation](https://doc.rust-lang.org/std/result/index.html).


Drawing Pixels
====================================================================================================
At this stage, we have code that brings up a window, connects to the GPU, and sets up a queue of
textures that is synchronized with the display. In Computer Graphics, the term "texture" is
generally used in the context of *texture mapping*, which is a technique to apply detail to geometry
using data stored in memory. A very common application is to map color data from the pixels of a 2D
image onto the surface of a 3D polygon.

Texture mapping is so essential to real-time graphics that all modern GPUs are equipped with
specialized hardware to speed up texture operations. It's not uncommon for a modern video game to
use texture assets that take up hundreds of megabytes. Processing all of that data involves a lot
of memory traffic which is a big performance bottleneck for a GPU. This is why GPUs come with
dedicated texture memory caches, sampling hardware, compression schemes and other features to
improve texture data throughput.

We are going to use the texture hardware to store the output of our renderer. In wgpu, a *texture
object* represents texture memory that can be used in three main ways: texture mapping, shader
storage, or as a *render target*[^ch3-cit1]. A surface texture is a special kind of texture that can
only be used as a render target.

Not all native APIs have this restriction. For instance, both Metal and Vulkan allow their version
of a surface texture -- a *frame buffer* (Metal) or *swap chain* (Vulkan) texture -- to be
configured for other usages, though this sometimes comes with a warning about impaired performance
and is not guaranteed to be supported by the hardware.

wgpu doesn't provide any other option so I'm going to start by implementing a render pass. This is
a fundamental and very widely used function of the GPU, so it's worth learning about.

[^ch3-cit1]: See [`wgpu::TextureUsages`](https://docs.rs/wgpu/0.17.0/wgpu/struct.TextureUsages.html).

The render Module
---------------------
I like to separate the rendering code from all the windowing code, so I'll start by creating a file
named `render.rs`. Every Rust file makes up a *module* (with the same name) which serves as a
namespace for all functions and types that are declared in it. Here I'll add a data structure called
`PathTracer`. This will hold all GPU resources and eventually implement our path tracing algorithm:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    pub struct PathTracer {
        device: wgpu::Device,
        queue: wgpu::Queue,
    }

    impl PathTracer {
        pub fn new(device: wgpu::Device, queue: wgpu::Queue) -> PathTracer {
            device.on_uncaptured_error(Box::new(|error| {
                panic!("Aborting due to an error: {}", error);
            }));

            // TODO: initialize GPU resources

            PathTracer {
                device,
                queue,
            }
        }
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [render-initial]: <kbd>[render.rs]</kbd> The PathTracer structure]

We start out with an associated function called `PathTracer::new` which will serve as the
constructor and eventually initialize all GPU resources. The `PathTracer` takes ownership of the
`wgpu::Device` and `wgpu::Queue` that we created earlier and it will hold on to them for the rest of
the application's life.

`wgpu::Device` represents a connection to the GPU. It is responsible for creating resources like
texture, buffer, and pipeline objects. It also defines some methods for error handling.

The first thing I do is set up an "uncaptured error" handler. If you look at the [declarations
](https://docs.rs/wgpu/0.17.0/wgpu/struct.Device.html) of resource creation methods you'll notice
that none of them return a `Result`. This doesn't mean that they always succeed, as a matter of fact
all of these operations can fail. This is because wgpu closely mirrors the WebGPU API which uses a
concept called *error scopes* to detect and respond to errors.

Whenever there's an error that I don't handle using an error scope it will trigger the uncaptured
error handler, which will print out an error message and abort the program[^ch3.1-cit1]. For now,
I won't set up any error scopes in `PathTracer::new` and I'll abort the program if the API fails to
create the initial resources.

Next, let's declare the `render` module and initialize a `PathTracer` in the `main` function:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
        ...
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Rust highlight

    mod render;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    const WIDTH: u32 = 800;
    const HEIGHT: u32 = 600;

    #[pollster::main]
    async fn main() -> Result<()> {
        let event_loop = EventLoop::new();
        let window_size = winit::dpi::PhysicalSize::new(WIDTH, HEIGHT);
        let window = WindowBuilder::new()
            .with_inner_size(window_size)
            .with_resizable(false)
            .with_title("GPU Path Tracer".to_string())
            .build(&event_loop)?;

        let (device, queue, surface) = connect_to_gpu(&window).await?;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Rust highlight
        let renderer = render::PathTracer::new(device, queue);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust

        event_loop.run(move |event, _, control_flow| {
            *control_flow = ControlFlow::Poll;
            match event {
                Event::WindowEvent { event, .. } => match event {
                    WindowEvent::CloseRequested => *control_flow = ControlFlow::Exit,
                    _ => (),
                },
                Event::RedrawRequested(_) => {
                    // Wait for the next available frame buffer.
                    let frame: wgpu::SurfaceTexture = surface
                        .get_current_texture()
                        .expect("failed to get current texture");

                    // TODO: draw frame

                    frame.present();
                }
                Event::MainEventsCleared => {
                    // draw repeatedly
                    window.request_redraw();
                }
                _ => (),
            }
        });
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [main-renderer-init]: <kbd>[main.rs]</kbd> Initializing a Renderer]

Now that we have the skeleton in place, it's time to paint some pixels on the screen.

[^ch3.1-cit1]: This is actually the default behavior so I didn't really need to call
`on_uncaptured_error`.

Display Pipeline
----------------
Before setting up the render pass let's first talk about how it works. Traditionally, graphics
systems have been modeled after an abstraction called the *graphics pipeline*.[^foley-vandam] At a
very high level, the input to the pipeline is a mathematical model that describes what to draw
-- such as geometry, materials, and light -- and the output is a 2D grid of pixels. This
transformation is processed in a series of standard *pipeline stages* which form the basis of the
rendering abstraction provided by GPUs and graphics APIs. wgpu uses the term *render pipeline* which
is what I'll use going forward.

The input to the render pipeline is a polygon stream represented by points in 3D space and their
associated data. The polygons are described in terms of geometric primitives (points, lines, and
triangles) which consist of *vertices*. The *vertex stage* transforms each vertex from the input
stream into a 2D coordinate space that corresponds to the viewport. After some additional processing
(such as clipping and culling) the assembled primitives are passed on to the *rasterizer*.
The rasterizer applies a process called scan conversion to determine the pixels that are covered by
each primitive and breaks them up into per-pixel *fragments*. The output of the vertex
stage (the vertex positions, texture coordinates, vertex colors, etc) gets interpolated between the
vertices of the primitive and the interpolated values get assigned to each fragment. Fragments are
then passed on to the *fragment stage* which computes an output (such as the pixel or sample color)
for each fragment. Shading techniques such as texture mapping and lighting are usually performed
in this stage. The output then goes through several other operations  before getting written to the
render target as pixels.[^ch3-footnote1]

  ![Figure [render-pipeline]:
    Vertex and Fragment stages of the render pipeline](../images/fig-01-render-pipeline.svg)

What I just described is very much a data pipeline: a data stream goes through a series of
transformations in stages. The input to each stage is defined in terms of smaller elements (e.g.
vertices and pixel-fragments) that can be processed in parallel. This is the fundamental principle
behind the GPU.

Early commercial GPUs implemented the graphics pipeline entirely in fixed-function hardware. Modern
GPUs still use fixed-function stages (and at much greater data rates) but virtually all of them
allow you to program the vertex and fragment stages with custom logic using *shader programs*.


[^ch3-footnote1]: I glossed over a few pipeline stages (such as geometry and tessellation) and
important steps like multi-sampling, blending, and the scissor/depth/stencil tests. These play an
important role in many real-time graphics applications but we won't make use of them in our path
tracer.

### Compiling Shaders

Let's put together a render pipeline that draws a red triangle. We'll define a vertex shader that
outputs the 3 corner vertices and a fragment shader that outputs a solid color. We'll write
these shaders in the WebGPU Shading Language (WGSL).

Go ahead and create a file called `shaders.wgsl` to host all of our WGSL code (I put it next to the
Rust files under `src/`). Before we can run this code on the GPU we need to compile it into a
form that can be executed on the GPU. We start by creating a *shader module*:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    pub struct PathTracer {
        device: wgpu::Device,
        queue: wgpu::Queue,
    }

    impl PathTracer {
        pub fn new(device: wgpu::Device, queue: wgpu::Queue) -> PathTracer {
            device.on_uncaptured_error(Box::new(|error| {
                panic!("Aborting due to an error: {}", error);
            }));


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
            let shader_module = compile_shader_module(&device);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust delete
            // TODO: initialize GPU resources
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust

            PathTracer {
                device,
                queue,
            }
        }
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight

    fn compile_shader_module(device: &wgpu::Device) -> wgpu::ShaderModule {
        use std::borrow::Cow;

        let code = include_str!(concat!(env!("CARGO_MANIFEST_DIR"), "/src/shaders.wgsl"));
        device.create_shader_module(wgpu::ShaderModuleDescriptor {
            label: None,
            source: wgpu::ShaderSource::Wgsl(Cow::Borrowed(code)),
        })
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [render-shader-module]: <kbd>[render.rs]</kbd> Creating the shader module]

The `compile_shader_module` function loads the file we just created into a string using the
`include_str!` macro. This bundles the contents of `shaders.wgsl` into the program binary at build
time. This is followed by a call to `wgpu::Device::create_shader_module` to compile the WGSL source
code.[^ch3-footnote2]

Let's define the vertex and fragment functions, which I'm calling `display_vs` and `display_fs`:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
    alias TriangleVertices = array&ltvec2f, 3>;
    var<private> vertices: TriangleVertices = TriangleVertices(
      vec2f(-0.5, -0.5),
      vec2f( 0.5, -0.5),
      vec2f( 0.0,  0.5),
    );

    @vertex fn display_vs(@builtin(vertex_index) vid: u32) -> @builtin(position) vec4f {
      return vec4f(vertices[vid], 0.0, 1.0);
    }

    @fragment fn display_fs() -> @location(0) vec4f {
      return vec4f(1.0, 0.0, 0.0, 1.0);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [vertex-and-fragment-shaders]: <kbd>[shaders.wgsl]</kbd> Vertex and Fragment shaders]

I'm using the "vs" and "fs" suffixes as shorthand for "vertex stage" and "fragment stage". Together,
these two functions form our "display pipeline" (the "display" part will become more clear later).
The `@vertex` and `@fragment` annotations are WGSL keywords that mark these two functions as entry
points to each pipeline stage program.

Since graphics workloads generally involve a high amount of linear algebra, GPUs natively support
SIMD operations over vectors and matrices. All shading languages define built-in types for vectors
and matrices of up to 4 dimensions (4x4 in the case of matrices). The `vec4f` and `vec2f` types that
are in the code represent 4D and 2D vectors of floating point numbers.

`display_vs` returns the vertex position as a `vec4f`. This position is defined relative to a
coordinate space called the *Normalized Device Coordinate Space*. In NDC, the center of the viewport
marks the origin $(0, 0, 0)$. The $x$-axis spans horizontally from $(-1, 0, 0)$ on the left edge of
the viewport to $(1, 0, 0)$ on the right edge while the $y$-axis spans vertically from $(0,-1,0)$ at
the bottom to $(0,1,0)$ at the top. The $z$-axis is directly perpendicular to the viewport, going
*through* the origin.

  ![Figure [ndc]: Our triangle in Normalized Device Coordinates](../images/fig-02-ndc.svg)

`display_vs` takes a *vertex index* as its parameter. The vertex function gets invoked for every
input vertex across different GPU threads. `vid` identifies the individual vertex that is assigned
to the *invocation*. The number of vertices and where they exist within the topology of the input
geometry is up to us to define. Since we want to draw a triangle, we'll later issue a *draw call*
with 3 vertices and `display_vs` will get invoked exactly 3 times with vertex indices ranging from
$0$ to $2$.

Since our 2D triangle is viewport-aligned, we can set the $z$ coordinate to $0$. The 4th
coordinate is known as a *homogeneous coordinate* used for projective transformations. Don't worry
about this coordinate for now -- just know that for a vector that represents a *position* we set
this coordinate to $1$. We can declare the $x$ and $y$ coordinates for the 3 vertices as an array
of `vec2f` and simply return the element that corresponds to `vid`. I enumerate the vertices in
counter-clockwise order which matches the winding order we'll specify when we create the pipeline.

`display_fs` takes no inputs and returns a `vec4f` that represents the fragment color. The 4
dimensions represent the red, green, blue, and alpha channels of the destination pixel. `display_fs`
gets invoked for all pixel fragments that result from our triangle and the invocations are executed
in parallel across many GPU threads, just like the vertex function. To paint the triangle solid red,
we simply return `vec4f(1., 0., 0., 1.)` for all fragments.

[^ch3-footnote2]: The `Cow::Borrowed` bit is a Rust idiom that creates a "copy-on-write borrow".
This allows the API to take ownership of the WGSL string if necessary. This is not really an
important detail for us.

### Creating the Pipeline Object

Before we can run the shaders, we need to assemble them into a *pipeline state object*. This is
where we specify the data layout of the render pipeline and link the shaders into a runnable binary
program. Let's add a new function called `create_display_pipeline`:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    ...
    fn compile_shader_module(device: &wgpu::Device) -> wgpu::ShaderModule {
        use std::borrow::Cow;

        let code = include_str!(concat!(env!("CARGO_MANIFEST_DIR"), "/src/shaders.wgsl"));
        device.create_shader_module(wgpu::ShaderModuleDescriptor {
            label: None,
            source: wgpu::ShaderSource::Wgsl(Cow::Borrowed(code)),
        })
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight

    fn create_display_pipeline(
        device: &wgpu::Device,
        shader_module: &wgpu::ShaderModule,
    ) -> wgpu::RenderPipeline {
        device.create_render_pipeline(&wgpu::RenderPipelineDescriptor {
            label: Some("display"),
            layout: None,
            primitive: wgpu::PrimitiveState {
                topology: wgpu::PrimitiveTopology::TriangleList,
                front_face: wgpu::FrontFace::Ccw,
                polygon_mode: wgpu::PolygonMode::Fill,
                ..Default::default()
            },
            vertex: wgpu::VertexState {
                module: shader_module,
                entry_point: "display_vs",
                buffers: &[],
            },
            fragment: Some(wgpu::FragmentState {
                module: shader_module,
                entry_point: "display_fs",
                targets: &[Some(wgpu::ColorTargetState {
                    format: wgpu::TextureFormat::Bgra8Unorm,
                    blend: None,
                    write_mask: wgpu::ColorWrites::ALL,
                })],
            }),
            depth_stencil: None,
            multisample: wgpu::MultisampleState::default(),
            multiview: None,
        })
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [display-pipeline]: <kbd>[render.rs]</kbd> The `create_display_pipeline` function]

This code describes a render pipeline that draws a list of triangle primitives. The vertex winding
order is set to counter-clockwise which defines the orientation of the triangle's *front
face*.[^ch3-footnote3]

We request that the interior of each polygon be completely filled (rather than drawing just the
edges or vertices). We specify that `display_vs` is the main function of the vertex stage and that
we're not providing any vertex data from the CPU (since we declared our vertices in the shader
code). Similarly, we set up a fragment stage with `display_fs` as the entry point and a single
color target.[^ch3-footnote4] I set the pixel format of the render target to `Bgra8Unorm`  since
that happens to be widely supported on all of my devices. What's important is that you assign a
pixel format that matches the surface configuration in your windowing setup and that your GPU device
supports this as a *render attachment* format.

Let's instantiate the pipeline and store it in the `PathTracer` object. Pipeline creation is
expensive so we want to create the pipeline state object once and hold on to it. We'll reference it
later when drawing a frame:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    pub struct PathTracer {
        device: wgpu::Device,
        queue: wgpu::Queue,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight

        display_pipeline: wgpu::RenderPipeline,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    }

    impl PathTracer {
        pub fn new(device: wgpu::Device, queue: wgpu::Queue) -> PathTracer {
            device.on_uncaptured_error(Box::new(|error| {
                panic!("Aborting due to an error: {}", error);
            }));

            let shader_module = compile_shader_module(&device);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
            let display_pipeline = create_display_pipeline(&device, &shader_module);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust

            PathTracer {
                device,
                queue,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
                display_pipeline,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
            }
        }
        ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [display-pipeline-init]: <kbd>[render.rs]</kbd> Initializing the display pipeline]


[^ch3-footnote3]: The GPU can automatically discard triangles that are oriented away from the
viewport. This is a feature called *back face culling* which our code doesn't make use of.

[^ch3-footnote4]: The `fragment` field of `wgpu::RenderPipelineDescriptor` is optional
(notice the *Some* in `Some(wgpu::FragmentState {...})` ?). A render pipeline that only outputs to
the depth or stencil buffers doesn't have to specify a fragment shader or any color attachments. An
example of this is *shadow mapping*: a shadow map is a texture that stores the distances between a
light source and geometry samples from the scene; it can be produced by a depth-only render-pass
from the point of view of the light source. The shadow map is later sampled from a render pass from
the camera's point of view to determine whether a rasterized point is visible from the light or in
shadow.

The Render Pass
---------------

We now have the pieces in place to issue a draw command to the GPU. The general abstraction modern
graphics APIs define for this is called a "command buffer" (or "command list" in D3D12). You can
think of the command buffer as a memory location that holds the serialized list of GPU commands
representing the sequence of actions we want the GPU to take. To draw a triangle we'll *encode*
a draw command into the command buffer and then *submit* the command buffer to the GPU for exection.

With wgpu, the encoding is abstracted by an object called `wgpu::CommandEncoder`, which we'll use to
record our draw command. Once we are done, we will call `wgpu::CommandEncoder::finish()` to produce
a finalized `wgpu::CommandBuffer` which we can submit to the GPU via the `wgpu::Queue` that we
created at start up.

Let's add a new `PathTracer` function called `render_frame`. This function will take a texture as
its parameter (our *render target*) and tell the GPU to draw to it using the pipeline object we
created earlier:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    ...
    impl PathTracer {
        ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
        pub fn render_frame(&self, target: &wgpu::TextureView) {
            let mut encoder = self
                .device
                .create_command_encoder(&wgpu::CommandEncoderDescriptor {
                    label: Some("render frame"),
                });

            let mut render_pass = encoder.begin_render_pass(&wgpu::RenderPassDescriptor {
                label: Some("display pass"),
                color_attachments: &[Some(wgpu::RenderPassColorAttachment {
                    view: target,
                    resolve_target: None,
                    ops: wgpu::Operations {
                        load: wgpu::LoadOp::Clear(wgpu::Color::BLACK),
                        store: wgpu::StoreOp::Store,
                    },
                })],
                ..Default::default()
            });

            render_pass.set_pipeline(&self.display_pipeline);

            // Draw 1 instance of a polygon with 3 vertices.
            render_pass.draw(0..3, 0..1);

            // End the render pass by consuming the object.
            drop(render_pass);

            let command_buffer = encoder.finish()
            self.queue.submit(Some(command_buffer));
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [render_frame-stub]: <kbd>[render.rs]</kbd> The `render_frame` function]

`target` here is defined as a `wgpu::TextureView`. wgpu makes the distinction between a texture
resource (represented by `wgpu::Texture`) and how that texture's memory is accessed by a pipeline
(which is represented by the *view* into the texture). When we want to bind a texture we first
create a view with the right properties. In this case we'll assume that the caller already created
a `TextureView` of the render target.

The first thing we do in `render_frame` is create a command encoder. We then tell the encoder to
begin a *render pass*. There are 4 important API calls we make to encode the draw command:

1. Create a `wgpu::RenderPass`. We tell it to store the colors that are output by the render
   pipeline to the `target` texture by assigning it as the only color attachment. We also tell it
   to clear all pixels of the target to black (i.e. $(0, 0, 0, 1)$ in RGBA) before drawing to it.

2. Assign the render pipeline.

3. Record a single draw with 3 vertices.

4. End the render pass by destroying the `wgpu::RenderPass` object.

We then serialize the command buffer and submit it to the GPU. Finally, let's invoke `render_frame`
from our windowing event loop, using the current surface texture as the render target:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    async fn main() -> Result<()> {
        ...
        event_loop.run(move |event, _, control_flow| {
                ...
                Event::RedrawRequested(_) => {
                    // Wait for the next available frame buffer.
                    let frame: wgpu::SurfaceTexture = surface
                        .get_current_texture()
                        .expect("failed to get current texture");


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust delete
                    // TODO: draw frame
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
                    let render_target = frame
                        .texture
                        .create_view(&wgpu::TextureViewDescriptor::default());

                    renderer.render_frame(&render_target);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust

                    frame.present();
                }
                ...
        });
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [render_frame-call]: <kbd>[render.rs]</kbd> Rendering to a surface texture]

Running this code should bring up a window that looks like this:

  ![Figure [first-triangle]: First Triangle](../images/img-02-first-triangle.png)

Finally drawing something! A single triangle may not look that interesting but you can model highly
complex 3D scenes and geometry by putting many of them together. It takes only a few tweaks to the
render pipeline to shape, animate, and render millions of triangles many times per second.


Full-Screen Quad
----------------
The render pipeline that we just put together plays a rather small role in the overall renderer:
its purpose is to display the output of the path-tracer on the window surface.

The output of our renderer is a 2D rectangular image and I would like it to fill the whole window.
We can achieve this by having the render pipeline draw two right triangles that are adjacent at
their hypothenuse. Remember that the viewport coordinates span the range $[-1, 1]$ in NDC, so
setting the 4 corners of the rectangle to $(-1, 1)$, $(1, 1)$, $(1, -1)$, $(-1, -1)$ should cover
the entire viewport regardless of its dimensions.


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift delete 
    alias TriangleVertices = array&ltvec2f, 3>;
    var<private> vertices: TriangleVertices = TriangleVertices(
      vec2f(-0.5, -0.5),
      vec2f( 0.5, -0.5),
      vec2f( 0.0,  0.5),
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
    alias QuadVertices = array&ltvec2f, 6>;
    var<private> vertices: TriangleVertices = TriangleVertices(
      vec2f(-1.0,  1.0),
      vec2f(-1.0, -1.0),
      vec2f( 1.0,  1.0),
      vec2f( 1.0,  1.0),
      vec2f(-1.0, -1.0),
      vec2f( 1.0, -1.0),
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    );

    @vertex fn display_vs(@builtin(vertex_index) vid: u32) -> @builtin(position) vec4f {
      return vec4f(vertices[vid], 0.0, 1.0);
    }

    @fragment fn display_fs() -> @location(0) vec4f {
      return vec4f(1.0, 0.0, 0.0, 1.0);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [quad-vertices]: <kbd>[shaders.wgsl]</kbd> Full-Screen Quad Vertices]


  ![Figure [half-screen-quad]: Half-Screen Triangle](../images/img-03-half-screen-quad.png)

That painted only one of the triangles. We also need to update the draw command with the new vertex
count:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    ...
    impl PathTracer {
        ...
        pub fn render_frame(&self, target: &wgpu::TextureView) {
            ...
            render_pass.set_pipeline(&self.display_pipeline);


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust delete
            // Draw 1 instance of a polygon with 3 vertices.
            render_pass.draw(0..3, 0..1);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
            // Draw 1 instance of a polygon with 6 vertices.
            render_pass.draw(0..6, 0..1);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust

            // End the render pass by consuming the object.
            drop(render_pass);

            let command_buffer = encoder.finish()
            self.queue.submit(Some(command_buffer));
        }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [render_frame-stub]: <kbd>[render.rs]</kbd> The `render_frame` function]


  ![Figure [full-screen-quad]: Full-Screen Quad](../images/img-04-full-screen-quad.png)


Viewport Coordinates
--------------------
In this setup, every fragment shader invocation outputs the color of a single pixel. We can identify
that pixel using the built-in `position` input to the pipeline stage.


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
    @fragment fn display_fs(@builtin(position) pos: vec4f) -> @location(0) vec4f {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
      return vec4f(1.0, 0.0, 0.0, 1.0);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [position-builtin]: <kbd>[shaders.wgsl]</kbd> Position Built-In]

The input is defined as a `vec4f`. The $x$ and $y$ coordinates are defined in the _Viewport
Coordinate System_. The origin $(0, 0)$ corresponds to the top-left corner pixel of the viewport.
The $x$-coordinate increases towards the right and the $y$-coordinate increases towards the bottom.
A whole number increment in $x$ or $y$ represents an increment by 1 pixel (and fractional increments
can fall "inside" a pixel). For example, for a viewport with the physical dimensions of
$800\times600$, the coordinate ranges are $0\le x\lt799, 0\le y \lt599$.

  ![Figure [viewport-coords]: Viewport Coordinate System](../images/fig-03-viewport-coords.svg)

Let's assign every pixel fragment a color based on its position in the viewport by mapping the
coordinates to a color channel (red and green). The render target uses a normalized color format
(i.e. the values must be between $0$ and $1$), so we divide each dimension by the largest possible
value to convert it to that range:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
    const WIDTH: u32 = 800u;
    const HEIGHT: u32 = 600u;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift

    @fragment fn display_fs(@builtin(position) pos: vec4f) -> @location(0) vec4f {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
      let color = pos.xy / vec2f(f32(WIDTH - 1u), f32(HEIGHT - 1u));
      return vec4f(color, 0.0, 1.0);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [pos-to-color]: <kbd>[shaders.wgsl]</kbd>]

There are two language expressions here that are worth highlighting. `pos.xy` is a so called
_vector swizzle_ that extracts the $x$ and $y$ components and produces a `vec2f` containing only
those. Next, we divide that `vec2f` by another `vec2f`. Here, the division operator performs a
component-wise division of every element of the vector on the left-hand side by the corresponding
element on the right-hand side, so `pos.xy / vec2f(f32(WIDTH - 1u), f32(HEIGHT - 1u))` is equivalent
to `vec2f(pos.x / f32(WIDTH - 1u), pos.y / f32(HEIGHT - 1u))`.

Now we are able to separately color each individual pixel. Running this should produce a picture
that looks like this:

  ![Figure [viewport-gradient]:
    Viewport Coordinates as a color gradient](../images/img-05-viewport-gradient.png)


Resource Bindings
====================================================================================================
Our program is split across separate runnable parts: the main executable that runs on the CPU and
pipelines that run on the GPU. As we add more features we will want to exchange data between the
different parts. The main way to achieve this is via memory resources.

The CPU side of our program can create and interact with resources by making API calls. On the GPU
side, the shader program can access those via _bindings_. A binding associates a resource with a
unique slot number that can be referenced by the shader. Each slot is identified by an index number.
The shader code declares a variable for each binding with a decoration that assigns it a binding
index. The CPU side is responsible for setting up the resources for a GPU pipeline according to its
binding layout.

WebGPU introduces an additional concept around bindings called _bind group_. A bind group
associates a group of resources that are frequently bound together.[^ch4-footnote1] Like individual
bindings, each bind group is identified by an index number. Our pipelines won't make use of more
than one bind group at a time, so we'll always assign $0$ as the group index.

[^ch4-footnote1]:  The bind group concept is similar to "descriptor set" in Vulkan, "descriptor
table" in D3D12, and "argument buffer" in Metal.


Uniform Declaration
-------------------
The first binding we are going to set up is a _uniform buffer_. Uniforms are read-only data that
don't vary across GPU threads. We are going to use a uniform buffer to store certain globals, like
camera parameters.

Our renderer currently assumes a window dimension of $800\times600$ and declares this in two
different places (`shaders.wgsl` and `main.rs`) which must be kept in sync. Let's make `WIDTH` and
`HEIGHT` uniforms and upload their values from the CPU side. We'll first declare a uniform buffer
and assign it to binding index $0$:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
    struct Uniforms {
      width: u32,
      height: u32,
    }
    @group(0) @binding(0) var<uniform> uniforms: Uniforms;

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift delete
    const WIDTH: u32 = 800u;
    const HEIGHT: u32 = 600u;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift

    @fragment fn display_fs(@builtin(position) pos: vec4f) -> @location(0) vec4f {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
      let color = pos.xy / vec2f(f32(uniforms.width - 1u), f32(uniforms.height - 1u));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
      return vec4f(color, 0.0, 1.0);
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [uniform binding declaration]: <kbd>[shaders.wgsl]</kbd> Uniform binding declaration]

The `var<uniform>` declaration tells the compiler that the shader expects a uniform buffer binding.
The type of the binding variable is `Uniforms` which represents the shader's view over the buffer's
memory. Declaring it this way allows the shader to access the contents of the buffer with an
expression like `uniforms.width`.


Bind Group Layout
-----------------
If you run the code now you should get a validation error telling you that the pipeline layout
expects a bind group layout at index $0$. We need to update the display pipeline description with a
layout that includes the new uniform binding. Let's update the `create_display_pipeline` function
to return a `wgpu::BindGroupLayout` alongside the pipeline object:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    impl PathTracer {
        pub fn new(device: wgpu::Device, queue: wgpu::Queue) -> PathTracer {
            device.on_uncaptured_error(Box::new(|error| {
                panic!("Aborting due to an error: {}", error);
            }));

            let shader_module = compile_shader_module(&device);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
            let (display_pipeline, display_layout) =
                create_display_pipeline(&device, &shader_module);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
            ...
        }
        ...
    }
    ...
    fn create_display_pipeline(
        device: &wgpu::Device,
        shader_module: &wgpu::ShaderModule,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
    ) -> (wgpu::RenderPipeline, wgpu::BindGroupLayout) {
        let bind_group_layout = device.create_bind_group_layout(&wgpu::BindGroupLayoutDescriptor {
            label: None,
            entries: &[
                wgpu::BindGroupLayoutEntry {
                    binding: 0,
                    visibility: wgpu::ShaderStages::FRAGMENT,
                    ty: wgpu::BindingType::Buffer {
                        ty: wgpu::BufferBindingType::Uniform,
                        has_dynamic_offset: false,
                        min_binding_size: None,
                    },
                    count: None,
                },
            ],
        });
        let pipeline = device.create_render_pipeline(&wgpu::RenderPipelineDescriptor {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
            label: Some("display"),
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
            layout: Some(&device.create_pipeline_layout(&wgpu::PipelineLayoutDescriptor {
                bind_group_layouts: &[&bind_group_layout],
                ..Default::default()
            })),
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
            ...
        });
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
        (pipeline, bind_group_layout)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [display-pipeline-layout]: <kbd>[render.rs]</kbd> Display pipeline layout]

This says that the pipeline contains a single bind group, containing a single buffer entry. The
buffer entry has the "uniform" buffer binding type and is visible only to the fragment stage.


Buffer Object
-------------
Let's now create the buffer object that will provide the backing memory for the uniforms. The
size and layout of the memory need to match the `Uniforms` struct that we declared in the WGSL. A
common pattern is to maintain two sets of these declarations (one for the CPU and one for the GPU
side) and keep them in sync. Some frameworks allow you to reuse the same declarations on both sides.
_wgpu_ doesn't provide a utility for this out of the box, so I'm going to redeclare `Uniforms` for
the CPU side:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
    use bytemuck::{Pod, Zeroable};
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust

    pub struct PathTracer {
        device: wgpu::Device,
        queue: wgpu::Queue,

        display_pipeline: wgpu::RenderPipeline,
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
    #[derive(Copy, Clone, Pod, Zeroable)]
    #[repr(C)]
    struct Uniforms {
        width: u32,
        height: u32,
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    impl PathTracer {
        ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [uniforms-struct-cpu]: <kbd>[render.rs]</kbd> CPU-side `Uniforms` struct]


The `repr(C)` attribute makes the memory layout of the `Uniforms` struct conform to the C language
rules so that the fields have a predictable order, size, and alignment.[^ch4-footnote2] For our
purposes, this should make the memory layout of the struct exactly match the WGSL declaration.

The `derive` attribute automatically implements the enumerated traits for our type. `Copy` and
`Clone` allow the type be copied by value (Rust types are move-only by default). This is also the
first time we are using the `bytemuck` crate. The `Pod` and `Zeroable` traits, along with `repr(C)`,
allow us the safely reinterpret the `Uniforms` struct as a sequence of bytes.

For all intents and purposes, these Rust attributes enable the same semantics as the following plain
C/C++ struct:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ C
    // If `Uniforms` were declared in C:
    struct Uniforms {
        uint32_t width;
        uint32_t height;
    };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Now, let's allocate the backing buffer object and initialize its contents:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    use bytemuck::{Pod, Zeroable};

    pub struct PathTracer {
        device: wgpu::Device,
        queue: wgpu::Queue,


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
        uniforms: Uniforms,
        uniform_buffer: wgpu::Buffer,


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
        display_pipeline: wgpu::RenderPipeline,
    }

    #[derive(Copy, Clone, Pod, Zeroable)]
    #[repr(C)]
    struct Uniforms {
        width: u32,
        height: u32,
    }

    impl PathTracer {
        pub fn new(device: wgpu::Device, queue: wgpu::Queue) -> PathTracer {
            device.on_uncaptured_error(Box::new(|error| {
                panic!("Aborting due to an error: {}", error);
            }));

            let shader_module = compile_shader_module(&device);
            let (display_pipeline, display_layout) =
                create_display_pipeline(&device, &shader_module);


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
            // Initialize the uniform buffer.
            let uniforms = Uniforms {
                width: 800,
                height: 600,
            };
            let uniform_buffer = device.create_buffer(&wgpu::BufferDescriptor {
                label: Some("uniforms"),
                size: std::mem::size_of::&ltUniforms&gt() as u64,
                usage: wgpu::BufferUsages::UNIFORM,
                mapped_at_creation: true,
            });
            uniform_buffer
                .slice(..)
                .get_mapped_range_mut()
                .copy_from_slice(bytemuck::bytes_of(&uniforms));
            uniform_buffer.unmap();


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
            PathTracer {
                device,
                queue,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
                uniforms,
                uniform_buffer,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
                display_pipeline,
            }
        }
        ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [uniforms-struct-cpu]: <kbd>[render.rs]</kbd> Uniform buffer object initialization]

This code allocates a buffer resource that is large enough to store an instance of `Uniforms` and
copies the contents of `uniforms` into it. The buffer is mapped at creation so that its address
space accessible to the CPU side. We also declare its usage to be `UNIFORM`: this is a hint to
the GPU driver that allows it to perform optimizations based on the buffer access pattern. The usage
is also useful for validating that the bindings we provide conform to the pipeline's layout.

After the data copy, we need to flush and unmap the buffer from CPU memory before we can use it in
GPU commands. We also store both `uniforms` and `uniform_buffer`, since we'll reuse them to modify
some of the uniforms at runtime.

[^ch4-footnote2]: The default Rust layout representation doesn't provide a strong guarantee on the
order of the fields. See the [Rust reference](https://doc.rust-lang.org/reference/type-layout.html#representations).

Bind Group
----------
We need to associate the buffer object with a bind group with the correct layout before it can be
used in a render pass. Let's create and store a bind group and assign it to group index $0$ while
encoding the draw:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    use bytemuck::{Pod, Zeroable};

    pub struct PathTracer {
        device: wgpu::Device,
        queue: wgpu::Queue,

        uniforms: Uniforms,
        uniform_buffer: wgpu::Buffer,

        display_pipeline: wgpu::RenderPipeline,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
        display_bind_group: wgpu::BindGroup,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    }

    #[derive(Copy, Clone, Pod, Zeroable)]
    #[repr(C)]
    struct Uniforms {
        width: u32,
        height: u32,
    }

    impl PathTracer {
        pub fn new(device: wgpu::Device, queue: wgpu::Queue) -> PathTracer {
            ...
            uniform_buffer.unmap();


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
            // Create the display pipeline bind group.
            let display_bind_group = device.create_bind_group(&wgpu::BindGroupDescriptor {
                label: None,
                layout: &display_layout,
                entries: &[wgpu::BindGroupEntry {
                    binding: 0,
                    resource: wgpu::BindingResource::Buffer(wgpu::BufferBinding {
                        buffer: &uniform_buffer,
                        offset: 0,
                        size: None,
                    }),
                }],
            });


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
            PathTracer {
                device,
                queue,
                uniforms,
                uniform_buffer,
                display_pipeline,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
                display_bind_group,
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
            }
        }

        pub fn render_frame(&self, target: &wgpu::TextureView) {
            ...
            render_pass.set_pipeline(&self.display_pipeline);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
            render_pass.set_bind_group(0, &self.display_bind_group, &[]);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust

            // Draw 1 instance of a polygon with 6 vertices
            render_pass.draw(0..6, 0..1);
            ...
        }
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [display-bind-group]: <kbd>[render.rs]</kbd>
     Creating and using the display bind group]

Running the program now should bring up the same picture as before. The viewport dimensions are
still hardcoded in two places so let's clean that up by making the viewport width and height
parameters of the `PathTracer` constructor:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    impl PathTracer {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
        pub fn new(
            device: wgpu::Device,
            queue: wgpu::Queue,
            width: u32,
            height: u32,
        ) -> PathTracer {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
            device.on_uncaptured_error(Box::new(|error| {
                panic!("Aborting due to an error: {}", error);
            }));

            let shader_module = compile_shader_module(&device);
            let (display_pipeline, display_layout) =
                create_display_pipeline(&device, &shader_module);

            // Initialize the uniform buffer.
            let uniforms = Uniforms {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
                width,
                height,
            };
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
            ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [width-height-parameters]: <kbd>[render.rs]</kbd>]

Let's update the main function to pass in the physical window dimensions while creating the
`PathTracer`:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust
    ...
    const WIDTH: u32 = 800;
    const HEIGHT: u32 = 600;

    #[pollster::main]
    async fn main() -> Result<()> {
        let event_loop = EventLoop::new();
        let window_size = winit::dpi::PhysicalSize::new(WIDTH, HEIGHT);
        let window = WindowBuilder::new()
            .with_inner_size(window_size)
            .with_resizable(false)
            .with_title("GPU Path Tracer".to_string())
            .build(&event_loop)?;

        let (device, queue, surface) = connect_to_gpu(&window).await?;

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust highlight
        let renderer = render::PathTracer::new(device, queue, WIDTH, HEIGHT);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Rust

        event_loop.run(move |event, _, control_flow| {
        ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [width-height-parameters-main]: <kbd>[main.rs]</kbd>]

Now we have a way to pass data between the CPU and GPU sides of the program. We can repeat
this pattern whenever we need to add or modify a bind group layout.


Ray Casting
====================================================================================================
Light flows out of emissive objects (like the sun or a lamp) and scatters off objects as it floods
the environment. When some of that light reaches a camera sensor, the camera can measure the amount
that arrived at each pixel and create a picture. Our virtual camera will compute the same
measurement by tracing the light's path in the reverse direction, starting at the camera and towards
the objects in the scene.

Camera Rays
-----------
The first segment in a path is between the camera and the closest surface that is visible "through
a pixel". To locate that surface, we can plot a ray from the camera and search for the closest
point where the ray intersects the scene.

A ray is a part of a straight line that has a starting point and extends infinitely in one
direction. A ray in 3D space can be represented using two vectors: a point of origin
$\vec{\mathbf{O}}$ and a direction $\vec{\mathbf{d}}$. All points $\mathbf{P}$ on the ray
are described by the linear equation $\mathbf{P}(t) = \mathbf{O} + t \mathbf{d}$ over the parameter
$t$. $t$ is a real number and its positive values represent points on the ray that are
in front of the origin (if we consider the direction $\mathbf{d}$ as _forward_). Negative values
of $t$ represent points behind the origin, and $t=0$ is the same as the origin.

Let's define the data structure to represent a ray:


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    struct Uniforms {
      width: u32,
      height: u32,
    }
    @group(0) @binding(0) var<uniform> uniforms: Uniforms;


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
    struct Ray {
      origin: vec3f,
      direction: vec3f,
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    alias QuadVertices = array<vec2f, 6>;
    ...
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [ray-struct]: <kbd>[shaders.wgsl]</kbd> Ray structure]


Let's model a simple pinhole camera. Initially we'll the define the eye position (where the arriving
light gets focused) as the camera's origin and this will act as the origin for all camera rays.
The camera has a view direction, and some distance away from the origin along the view direction
sits the 2D viewport framing the rendered image.

We will initially position the camera origin at $(0, 0, 0)$ and set the view direction towards the
$-z$-axis in a 3-dimensional right-handed cartesian coordinate system.

  ![Figure [ndc]: Rays in camera coordinates](../images/fig-04-camera-view-space.svg)

In order to determine the direction for the ray going through a pixel, we need to translate the
pixel's viewport coordinates to the coordinate system we are going to use when computing ray
intersections. Let's define the $x$ and $y$ coordinate span of the viewport as NDC (ranging from
$-1$ to $1$) and let's offset that by some fixed distance along the $-z$-axis. This makes the
viewport a square (with a width and height of 2 units) so we need to adjust it by the aspect ratio
of the application window in order to make the shape of the viewport match our frame.

Our fragment shader currently normalizes the viewport pixel coordinates to the range $[0,1]$ and
returns that as the output color. We can apply a simple transformation to map the coordinates to our
new camera coordinate space:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    ...
    @fragment fn display_fs(@builtin(position) pos: vec4f) -> @location(0) vec4f {
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift delete
      let color = pos.xy / vec2f(f32(uniforms.width - 1u), f32(uniforms.height - 1u));
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
      let origin = vec3(0.);
      let focus_distance = 1.;
      let aspect_ratio = f32(uniforms.width) / f32(uniforms.height);

      // Map `pos` from y-down viewport coordinates to camera viewport plane coordinates.
      var uv = pos.xy / vec2f(f32(uniforms.width - 1u), f32(uniforms.height - 1u));
      uv = vec2(uv.x - 0.5, 0.5 - uv.y) * vec2(1., aspect_ratio);

      let direction = vec3(uv, -focus_distance);
      let ray = Ray(origin, direction);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
      ...
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [camera-ray-computation]:
     <kbd>[shaders.wgsl]</kbd> Deriving the camera ray origin and direction]


Now we have our camera ray but we don't have any objects in the scene for it to intersect. Initially
we can make all rays hit the sky which will also act as our first light source. We can make the sky
appear a little more realistic by painting it with a gradient that blends from white to blue as the
$y$ coordinate of the ray's direction increases. We'll first map the $y$ coordinate to the $[0,1]$
range and use that value to linearly interpolate between the two colors using the blend equation:

  $$ \mathit{blendedValue} = (1-a)\cdot\mathit{startValue} + a\cdot\mathit{endValue} $$

Let's introduce a function called `sky_color` to compute this for a given ray and return that as the
fragment color. I'm using the same colors as RTIOW but you could instead blend any two colors that
you prefer:

    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    ...
    struct Ray {
      origin: vec3f,
      direction: vec3f,
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
    fn sky_color(ray: Ray) -> vec3f {
      let t = 0.5 * (normalize(ray.direction).y + 1.);
      return (1. - t) * vec3(1.) + t * vec3(0.3, 0.5, 1.);
    }


    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    ...
    @fragment fn display_fs(@builtin(position) pos: vec4f) -> @location(0) vec4f {
      let origin = vec3(0.);
      let focus_distance = 1.;
      let aspect_ratio = f32(uniforms.width) / f32(uniforms.height);

      // Map `pos` from y-down viewport coordinates to camera viewport plane coordinates.
      var uv = pos.xy / vec2f(f32(uniforms.width - 1u), f32(uniforms.height - 1u));
      uv = vec2(uv.x - 0.5, 0.5 - uv.y) * vec2(1., aspect_ratio);

      let direction = vec3(uv, -focus_distance);
      let ray = Ray(origin, direction);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift highlight
      return vec4(sky_color(ray), 1.);
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Swift
    }
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    [Listing [camera-ray-computation]:
     <kbd>[shaders.wgsl]</kbd> Deriving the camera ray origin and direction]

Running the program now should produce an image that looks like this:

  ![Figure [sky]: Ray tracing the sky](../images/img-06-sky-gradient.png)


Sphere Intersection
-------------------
TODO

Temporal Antialiasing
====================================================================================================
Accumulating Samples
--------------------

Diffuse Material
====================================================================================================

Interactive Camera
====================================================================================================


TODO
====
- Path tracing stochastic explainer when it's time to talk about RNG.

References
==========
[^foley-vandam]: J.F. Hughes, A. van Dam, M. McGuire, D.F. Sklar, J.D. Foley, S.K. Feiner, K. Akeley *Computer Graphics: Principles and Practice, 3rd Edition, Section 1.6*

[Arman Uguray]:       https://github.com/armansito
[Steve Hollasch]:     https://github.com/hollasch
[Trevor David Black]: https://github.com/trevordblack
[RTIOW]:              https://raytracing.github.io/books/RayTracingInOneWeekend.html
[rt-project]:         https://github.com/RayTracing/
[gt-project]:         https://github.com/RayTracing/gpu-tracing/
[gt-template]:        https://github.com/RayTracing/gpu-tracing/blob/dev/code/template
[discussions]:        https://github.com/RayTracing/gpu-tracing/discussions/
[dxr]:                https://en.wikipedia.org/wiki/DirectX_Raytracing
[vkrt]:               https://www.khronos.org/blog/ray-tracing-in-vulkan
[rtiow-cuda]:         https://developer.nvidia.com/blog/accelerated-ray-tracing-cuda/
[webgpu]:             https://www.w3.org/TR/webgpu/
[Rust]:               https://www.rust-lang.org/
[rust-unsafe]:        https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html
[wgpu]:               https://wgpu.rs

<!-- Markdeep: https://casual-effects.com/markdeep/ -->
<link rel='stylesheet' href='../style/book.css'>
<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js"></script>
<script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
